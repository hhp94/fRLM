---
title: "modding"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{modding}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## fRLM_lpfr
```{r}
library(rstan)
library(fRLM)
options(mc.cores = 4)

# Gaussian outcome
debug(fRLM_lpfr)

fit <- fRLM_lpfr(
  data = toy,
  id = "id",
  # string, name of the subject identifier
  exposures = "exposure",
  # string, the variable name of the exposures (for now, one)
  outcome = "outcome",
  # string, the variable name of the outcome
  time = "age",
  # string, the variable name of the time at which measures were taken
  warmup = 500,
  iter = 1000,
  chains = 4
)

undebug(fRLM_lpfr)

plot(fit)
w = predict(fit)
```

```{r}
rstan::extract(fit$fit)$xi |> class()
rstan::extract(fit$fit)$xi |> head()
```

```{r}
library(cmdstanr)
cmdstanr_example("schools")
```

```{r}
library(cmdstanr)
debug(fRLM_lpfr1)
fit1 <- fRLM_lpfr1(
  data = toy,
  id = "id",
  # string, name of the subject identifier
  exposures = "exposure",
  # string, the variable name of the exposures (for now, one)
  outcome = "outcome",
  # string, the variable name of the outcome
  time = "age",
  # string, the variable name of the time at which measures were taken
  sample_args = list(
    refresh = 100,
    parallel_chains = 4,
    iter_warmup = 1000,
    iter_sampling = 1000
  )
)
undebug(fRLM_lpfr1)
```

```{r}
plot(fit1)
```

## plugins
## Example
```{r setup, message=FALSE}
library(fRLM)
library(dplyr)
# parallel computing for the bayesian fit:
# library("rstan") # observe startup messages
# options(mc.cores = parallel::detectCores())
# rstan_options(auto_write = TRUE)
```

### 1) Data setup:
```{r setup data, results='hide'}
head(toy) # toy example dataset
toy2 <- toy
toy2[, 4] <- round( ( toy[, 4] - 10 ) / 30, 2 ) # i. rescale age:
y <- toy2 %>% group_by(id) %>% summarise(outcome = mean(outcome) ) %>% pull(outcome) # extract outcome:
t_obs <- toy2 %>% group_by(id) %>% summarise(age = list(age)) %>%  pull(age) # extract age
exposure <- toy2 %>% group_by(id) %>% summarise(exposure = list(exposure)) %>%  pull(exposure) # extract exposure
```

### 2) Fit gaussian processes:
```{r Fit gaussian processes}
gpfitList <- lapply(
  1:length(y), function(i) {
    gpFit(t_obs[[i]], exposure[[i]])
  })

grid <- seq(0, 1, l = 150)
pred <- t(sapply(gpfitList, predict, tnew = grid))

i <- 5
plot(gpfitList[[i]])
plot(1:150, pred[i,])
```

### 3) Frequentist Estimation:
```{r Frequentist Estimation}
fit <- funcReg( y, pred, grid = grid, L = 5 )
bootfit <- bootFunReg( y, pred, grid = grid, L = 5 )
plot(bootfit, ylim = c(0, 3))
```

### 5) Bayesian Estimation:
```{r Bayesian Estimation, results='hide', message=FALSE}
fitBayes <- funcReg_bayes1(
  y,
  pred,
  L = 5,
  sample_args = list(
    refresh = 100,
    parallel_chains = 4,
    iter_warmup = 1000,
    iter_sampling = 1000
  )
)
plot(fitBayes)
```

### Testing:
```{r Testing, results='hide', message=FALSE}
is_lmhyp_available <- require("lmhyp")
if (!is_lmhyp_available) {
  devtools::install_github("Jaeoc/lmhyp")
}
library(lmhyp)
library(stringi)
library(stringr)
library(purrr)
library(tidyr)
library(tibble)

# composite test: Accumulation, sensitive, critical
n_period <- 3
paritions <- cbind(1:n_period - 1, 1:n_period) / n_period
colnames(paritions) <- c("l", "u")
post_w <- get_post_weights(fitBayes, paritions)
composite_test(post_w)

# Finest credible intervals:
get_FCI( post_w )
```
